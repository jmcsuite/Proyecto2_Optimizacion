{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a248eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5d4bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Utils.readUtils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9f02b1",
   "metadata": {},
   "source": [
    "# Experimento 1: Autoencoder\n",
    "\n",
    "- Hidden layer de 100\n",
    "- Input distinto en cada ciclo de entrenamiento\n",
    "- 1000*1000 funciona\n",
    "- Input es el vector sin ningún tratamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df786a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (11, 12)\n"
     ]
    }
   ],
   "source": [
    "# Generate set of data for training cycle\n",
    "def genData(nMaquinas, nOrdenes, cant):\n",
    "    matrix = []\n",
    "    for i in range(cant):\n",
    "        a = Utils.readUtils.solucionAleatoria(nMaquinas, nOrdenes)\n",
    "        matrix.append(a)\n",
    "    X = torch.Tensor(matrix)\n",
    "    return X\n",
    "\n",
    "a = genData(nMaquinas, nOrdenes, 11).to(device);\n",
    "print(\"X: \", tuple(a.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2117a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem parameters\n",
    "\n",
    "nMaquinas = 3\n",
    "nOrdenes = 10\n",
    "matrizProcesamiento = []\n",
    "matrizAjustes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ea90df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y: (11, 12)\n"
     ]
    }
   ],
   "source": [
    "## Setup model\n",
    "\n",
    "N = nOrdenes + nMaquinas - 1 # input layer\n",
    "M = 100 # Encoded Layer\n",
    "H = 100 # Hidden layer\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(N, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, M),\n",
    "    torch.nn.Linear(M, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, N)\n",
    ")\n",
    "model.to(device)\n",
    "b = model(a)\n",
    "print(\"Y:\", tuple(b.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23c09484",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learning parameters\n",
    "learning_rate = 1e-3\n",
    "lambda_l2 = 1e-5\n",
    "\n",
    "# compute squared differences of each element\n",
    "# Typically used in regressions\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "#Stochastic gradient descent\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)\n",
    "\n",
    "it = 1000\n",
    "nInputs = 1000 #number of samples per training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e962acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "\n",
    "for i in range(it):\n",
    "    # Generate input\n",
    "    X = genData(nMaquinas, nOrdenes, nInputs).to(device)\n",
    "    #Feed forward\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    #compute loss function\n",
    "    #Since it is an autoencoder, our output is the input\n",
    "    loss = criterion(y_pred, X)\n",
    "    \n",
    "    #Clear gradient\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Backprop\n",
    "    loss.backward()\n",
    "    \n",
    "    #Apply changes\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b26a8a4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (635209548.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_4383/635209548.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    a =\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a =\n",
    "\n",
    "b = model(a)\n",
    "\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73bce3e",
   "metadata": {},
   "source": [
    "### Experimento 1:\n",
    "\n",
    "#### Autoencoder?? De 12 -> 100 -> 2 -> 100 -> 12\n",
    "#### Fracaso total xd\n",
    "\n",
    "Ideas:  \n",
    "- Usar un input que sea de 0ros y 1nos\n",
    "- Entrenar  sin la capa intermedia de 100??\n",
    "- Entrenar siempre con los mismos datos.. ( En este caso ando generando datos nuevos siempre)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809d53b",
   "metadata": {},
   "source": [
    "# Experimento 2:\n",
    "- Igual que el experimento 1\n",
    "- mismo input siempre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6ac246b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=12, out_features=100, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=100, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Setup model\n",
    "\n",
    "N = nOrdenes + nMaquinas - 1 # input layer\n",
    "M = 2 # Encoded Layer\n",
    "H = 100 # Hidden layer\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(N, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, N)\n",
    ")\n",
    "model.to(device)\n",
    "#b = model(a)\n",
    "# print(\"Y:\", tuple(b.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "eca3a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learning parameters\n",
    "learning_rate = 1e-3\n",
    "lambda_l2 = 1e-5\n",
    "\n",
    "# compute squared differences of each element\n",
    "# Typically used in regressions\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "#Stochastic gradient descent\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)\n",
    "\n",
    "it = 1000\n",
    "nInputs = 100000 #number of samples per training\n",
    "a = genData(nMaquinas, nOrdenes, nInputs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f247b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "\n",
    "for i in range(it):\n",
    "    # Generate input\n",
    "    X = a\n",
    "    #Feed forward\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    #compute loss function\n",
    "    #Since it is an autoencoder, our output is the input\n",
    "    loss = criterion(y_pred, X)\n",
    "    \n",
    "    #Clear gradient\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Backprop\n",
    "    loss.backward()\n",
    "    \n",
    "    #Apply changes\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "27e9f16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  9., -1.,  6.,  8.,  7.,  4.,  5.,  1.,  0., -1.,  2.],\n",
      "        [ 3.,  2.,  4.,  6.,  8.,  1.,  0.,  5.,  9.,  7., -1., -1.],\n",
      "        [ 9., -1.,  6.,  7.,  5.,  0.,  8.,  2.,  4.,  1.,  3., -1.],\n",
      "        [ 2.,  7., -1.,  8.,  0.,  6.,  1.,  3.,  5.,  9., -1.,  4.],\n",
      "        [ 2.,  8.,  7.,  6.,  3.,  9.,  5.,  1.,  4., -1., -1.,  0.]],\n",
      "       device='cuda:0') tensor([[ 3.6903,  8.0572, -0.5415,  5.9323,  7.4280,  6.2936,  4.3900,  5.2022,\n",
      "          1.1026,  0.0383,  0.7620,  1.4483],\n",
      "        [ 3.3845,  2.3230,  4.0359,  6.2135,  7.7760,  0.6507, -0.1871,  5.3455,\n",
      "          9.0024,  6.0921, -0.9503, -0.3146],\n",
      "        [ 8.7503,  0.1826,  5.4761,  5.9357,  5.2146,  1.0011,  7.0730,  2.1545,\n",
      "          3.5383,  1.4534,  2.6043,  0.3694],\n",
      "        [ 2.1817,  5.6620,  0.1400,  7.9497,  0.0579,  5.9422,  1.4233,  2.8887,\n",
      "          5.4412,  8.5439,  0.0837,  3.4461],\n",
      "        [ 2.1798,  8.1868,  7.1006,  5.4636,  2.6230,  8.8624,  5.3294,  1.1237,\n",
      "          4.2602, -1.0054, -0.8053, -0.0611]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "a = a\n",
    "\n",
    "b = model(a[3:8])\n",
    "\n",
    "print(a[3:8], b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f8f57",
   "metadata": {},
   "source": [
    "### Notas del experimento 2, un fracaso jaja. Pero al parecer funciona cuando solo intentamos input de tamaño 2 ( osea siempre los dos vectores lol) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2bdfa6",
   "metadata": {},
   "source": [
    "# Experimento 3:\n",
    "## Igual al experimento2 y al experimento 1, pero usare un input de puros 0 y 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8a6ace06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 4., 2., 1., 1., 3., 0., 3., 4., 4., 4.],\n",
      "        [0., 1., 3., 1., 0., 0., 4., 4., 1., 3., 2., 3.],\n",
      "        [4., 3., 4., 1., 2., 4., 0., 4., 4., 4., 3., 3.],\n",
      "        [4., 2., 3., 4., 2., 3., 2., 4., 4., 4., 1., 4.],\n",
      "        [0., 0., 0., 4., 2., 2., 3., 0., 4., 2., 4., 3.],\n",
      "        [0., 3., 3., 0., 0., 1., 2., 3., 0., 3., 0., 3.],\n",
      "        [0., 0., 0., 2., 4., 3., 2., 1., 0., 0., 1., 3.],\n",
      "        [1., 3., 1., 3., 4., 2., 3., 2., 3., 0., 3., 0.],\n",
      "        [4., 0., 3., 0., 1., 0., 2., 1., 1., 3., 2., 2.],\n",
      "        [2., 4., 4., 2., 2., 4., 2., 3., 4., 4., 2., 2.],\n",
      "        [0., 1., 4., 3., 1., 4., 1., 4., 1., 0., 0., 3.]], device='cuda:0')\n",
      "X:  (11, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10317/3116986477.py:6: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  X = torch.IntTensor(X)\n"
     ]
    }
   ],
   "source": [
    "# Generate set of data for training cycle\n",
    "def genData(nMaquinas, nOrdenes, cant):\n",
    "    \n",
    "    X = torch.rand(cant, nMaquinas + nOrdenes -1)*5\n",
    "    X = X.tolist()\n",
    "    X = torch.IntTensor(X)\n",
    "    X = X.tolist()\n",
    "    X = torch.FloatTensor(X)\n",
    "    return X\n",
    "\n",
    "a = genData(nMaquinas, nOrdenes, 11).to(device);\n",
    "print(a)\n",
    "print(\"X: \", tuple(a.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7052e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b41bf2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Problem parameters\n",
    "\n",
    "nMaquinas = 3\n",
    "nOrdenes = 10\n",
    "matrizProcesamiento = []\n",
    "matrizAjustes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8bca0cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y: (11, 12)\n"
     ]
    }
   ],
   "source": [
    "## Setup model\n",
    "\n",
    "N = nOrdenes + nMaquinas - 1 # input layer\n",
    "M = 2 # Encoded Layer\n",
    "H = 100 # Hidden layer\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(N, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, M),\n",
    "    torch.nn.Linear(M, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, N)\n",
    ")\n",
    "model.to(device)\n",
    "b = model(a)\n",
    "print(\"Y:\", tuple(b.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "95715f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10317/3116986477.py:6: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  X = torch.IntTensor(X)\n"
     ]
    }
   ],
   "source": [
    "## Learning parameters\n",
    "learning_rate = 1e-3\n",
    "lambda_l2 = 1e-5\n",
    "\n",
    "# compute squared differences of each element\n",
    "# Typically used in regressions\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "#Stochastic gradient descent\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)\n",
    "\n",
    "it = 1000\n",
    "nInputs = 1000 #number of samples per training\n",
    "\n",
    "a = genData(nMaquinas, nOrdenes, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8b8be839",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "\n",
    "for i in range(it):\n",
    "    # Generate input\n",
    "    X = a\n",
    "    #Feed forward\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    #compute loss function\n",
    "    #Since it is an autoencoder, our output is the input\n",
    "    loss = criterion(y_pred, X)\n",
    "    \n",
    "    #Clear gradient\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Backprop\n",
    "    loss.backward()\n",
    "    \n",
    "    #Apply changes\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9362def9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 1., 2., 3., 4., 4., 1., 3., 1., 3., 2., 2.], device='cuda:0') tensor([1.9820, 2.1149, 3.4068, 2.8510, 3.3862, 2.4827, 1.9500, 3.2198, 1.5294,\n",
      "        2.0661, 1.3149, 1.4737], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "b = model(a[3])\n",
    "\n",
    "print(a[3], b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23245b33",
   "metadata": {},
   "source": [
    "# Ahora si, lo cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f34731fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = maquinas,\n",
    "# D = ordenes\n",
    "def generateBatch(batchSize, M, D):\n",
    "    r\"\"\"\n",
    "        Recibe el tamaño de entradas por ciclo de entrenamiento, numero de maquinas y \n",
    "        numero de ordenes.  \n",
    "        Regresa una matriz de batchsize x (D + M -1) x (D + 1) que representa varias secuencias\n",
    "    \"\"\"\n",
    "    # Generate all data\n",
    "    x = genData(M, D, batchSize)   \n",
    "    \n",
    "    # Each input must be a (D + M-1) x (D + 1)\n",
    "    y = torch.zeros((batchSize, (D + M -1), (D+1)))\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(x[i])):\n",
    "            y[i][j][int(x[i][j] + 1)] = 1\n",
    "    \n",
    "        \n",
    "    return y\n",
    "\n",
    "def decodePred(pred):\n",
    "    copyPred = pred.clone().long()\n",
    "    index = torch.argmax(copyPred, dim = 1)\n",
    "    return index\n",
    "\n",
    "def printPred(pred):\n",
    "    index = decodePred(pred)\n",
    "    machine = 1\n",
    "    print(\"Machine \", machine, \": \", end = \"\", sep = \"\")\n",
    "    for i in index:\n",
    "        if(i == 0):\n",
    "            machine += 1\n",
    "            print(\"\\nMachine \", machine, \": \", end = \"\", sep = \"\")\n",
    "        else:\n",
    "            print(i.item(), end = \" \")\n",
    "    print()\n",
    "    \n",
    "def isValid(pred, nMaquinas, nOrdenes):\n",
    "    index = decodePred(pred)\n",
    "    count = 0\n",
    "    seq = set()\n",
    "    for a in index:\n",
    "        seq.add(a)\n",
    "        if(a == 0):\n",
    "            count += 1\n",
    "    if(len(seq) == nMaquinas + nOrdenes - 1 and count == nMaquinas - 1):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4351d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n",
      "torch.Size([3, 12, 11])\n",
      "\n",
      "torch.Size([3, 12, 11])\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.5063],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3585],\n",
      "         [0.1397, 0.0000, 0.0000, 0.1529],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3019],\n",
      "         [0.0000, 0.4088, 0.0000, 0.2468],\n",
      "         [0.0000, 0.1111, 0.0000, 0.6509],\n",
      "         [0.0000, 0.0000, 0.0000, 0.1635],\n",
      "         [0.0000, 0.0000, 0.0000, 0.2643],\n",
      "         [0.0000, 0.0000, 0.0000, 0.1899],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.2627],\n",
      "         [0.0000, 0.3097, 0.0000, 0.3157]],\n",
      "\n",
      "        [[0.1841, 0.0000, 0.0000, 0.2316],\n",
      "         [0.0000, 0.0000, 0.0000, 0.1940],\n",
      "         [0.0237, 0.2063, 0.0000, 0.6392],\n",
      "         [0.0000, 0.2356, 0.0000, 0.2444],\n",
      "         [0.0000, 0.0000, 0.0000, 0.2600],\n",
      "         [0.0000, 0.0000, 0.0000, 0.2806],\n",
      "         [0.0000, 0.0000, 0.0000, 0.2386],\n",
      "         [0.0000, 0.4150, 0.0000, 0.2607],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.2627],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4120],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4158]],\n",
      "\n",
      "        [[0.1841, 0.0000, 0.0000, 0.2316],\n",
      "         [0.0000, 0.0000, 0.0000, 0.2838],\n",
      "         [0.0000, 0.3077, 0.0000, 0.3111],\n",
      "         [0.0000, 0.0000, 0.0000, 0.2494],\n",
      "         [0.0000, 0.0000, 0.0000, 0.2079],\n",
      "         [0.0000, 0.0000, 0.0000, 0.4241],\n",
      "         [0.0000, 0.0000, 0.0000, 0.2071],\n",
      "         [0.0221, 0.2050, 0.0000, 0.6364],\n",
      "         [0.0000, 0.0000, 0.0000, 0.1194],\n",
      "         [0.0000, 0.4267, 0.0000, 0.2869],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.5063]]], grad_fn=<TransposeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "class SimpleRNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # This just calls the base class constructor\n",
    "        super().__init__()\n",
    "        # Neural network layers assigned as attributes of a Module subclass\n",
    "        # have their parameters registered for training automatically.\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = torch.nn.RNN(input_size, hidden_size, nonlinearity='relu', batch_first=True)\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros((1,x.size()[0], self.hidden_size))\n",
    "        h, _ = self.rnn(x, h0)\n",
    "        x = self.linear(h)\n",
    "        return x, h\n",
    "\n",
    "N = 10 # tareas\n",
    "M = 3 # maquinas\n",
    "model = SimpleRNN(11, 4, 11)\n",
    "a = generateBatch(3, M, N)\n",
    "print(a[1])\n",
    "print(a.size())\n",
    "y, yy = model(a)\n",
    "print()\n",
    "print(y.size())\n",
    "print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9770de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine 1: 5 7 3 \n",
      "Machine 2: 4 8 9 6 1 10 2 \n",
      "Machine 3: \n",
      "tensor([[ 5,  7,  3,  0,  4,  8,  9,  6,  1, 10,  2,  0]])\n"
     ]
    }
   ],
   "source": [
    "N = 10 # tareas\n",
    "M = 3 # maquinas\n",
    "H = 100 # hidden\n",
    "it = 100\n",
    "batchSize = 32\n",
    "\n",
    "model = SimpleRNN(N+1, H, N+1)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr = 0.001)\n",
    "\n",
    "\n",
    "model.train()\n",
    "corrects = 0\n",
    "\n",
    "for i in range(it):\n",
    "    #get data\n",
    "    X = generateBatch(batchSize, M, N)\n",
    "    \n",
    "    # Feed forward\n",
    "    y_pred, h_pred = model(X)\n",
    "    #y_pred = y_pred[:, -1, :]\n",
    "    #print(y_pred)\n",
    "    \n",
    "    Y = X.argmax(dim = 2)\n",
    "    #Y = Y[-1]\n",
    "    #Y = Y[:, -1]\n",
    "    #print(Y)\n",
    "    # Loss Function\n",
    "    #print(Y.size(), y_pred.size())\n",
    "    loss = criterion(y_pred.view(32*12, -1), Y.view(-1))\n",
    "    \n",
    "    # Clear gradient\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # BackProp \n",
    "    loss.backward()\n",
    "    \n",
    "    #Gradient descent\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "a = generateBatch(1, M, N)\n",
    "printPred(a[0])\n",
    "b, _ = model(a)\n",
    "b = b.argmax(dim = 2)\n",
    "print(b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f693f2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine 1: 7 \n",
      "Machine 2: 1 3 5 8 4 \n",
      "Machine 3: 6 9 2 10 \n",
      "True\n",
      "tensor([[ 7,  0,  1,  3,  5,  8,  4,  0,  6,  9,  2, 10]])\n"
     ]
    }
   ],
   "source": [
    "a = generateBatch(1, M, N)\n",
    "printPred(a[0])\n",
    "b, _ = model(a)\n",
    "print(isValid(b[0], M, N))   \n",
    "b = b.argmax(dim = 2)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "325dc3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1000.) 1000\n",
      "torch.Size([12, 100])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "it = 1000\n",
    "correct = 0\n",
    "valid = 0\n",
    "for i in range(1):\n",
    "    #get data\n",
    "    X = generateBatch(it, M, N)\n",
    "    \n",
    "    # Feed forward\n",
    "    y_pred, h_pred = model(X)\n",
    "    valid = [isValid(y, M, N) for y in y_pred]\n",
    "    #y_pred = y_pred[:, -1, :]\n",
    "    #print(y_pred)\n",
    "    y_pred = y_pred.argmax(dim = 2)\n",
    "    Y = X.argmax(dim = 2)\n",
    "    \n",
    "    correct = (y_pred == Y).sum() / 12\n",
    "vv = 0\n",
    "for v in valid:\n",
    "    if(v == True):\n",
    "        vv += 1\n",
    "valid = vv\n",
    "    \n",
    "print(correct, valid)\n",
    "print(h_pred[-1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6454afa",
   "metadata": {},
   "source": [
    "# Exito, funciona el autoencoder\n",
    "\n",
    "## Solo falta que funcione funcione jajaja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42d54ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 12, 11])\n",
      "no list\n",
      "list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ComplexRNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # This just calls the base class constructor\n",
    "        super().__init__()\n",
    "        # Neural network layers assigned as attributes of a Module subclass\n",
    "        # have their parameters registered for training automatically.\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = torch.nn.RNN(input_size, hidden_size, nonlinearity='relu', batch_first=True)\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.rnn2 = torch.nn.RNN(input_size, hidden_size, nonlinearity='relu',batch_first=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros((1, x.size()[0], self.hidden_size)).to(device)\n",
    "        _, hn = self.rnn(x, h0)\n",
    "        xDummy = torch.zeros(x.size()).to(device)\n",
    "        h2n, _ = self.rnn2(xDummy, hn)\n",
    "        y = self.linear(h2n)\n",
    "        return y, hn\n",
    "    \n",
    "class ThrashRNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # This just calls the base class constructor\n",
    "        super().__init__()\n",
    "        # Neural network layers assigned as attributes of a Module subclass\n",
    "        # have their parameters registered for training automatically.\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = torch.nn.RNN(input_size, hidden_size, nonlinearity='relu', batch_first=True)\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
    "        self.rnn2 = torch.nn.RNN(hidden_size, hidden_size, nonlinearity='relu',batch_first=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Batch, sequence lenght and input size\n",
    "        N, L, Hin = tuple(x.size())\n",
    "        # compute first rnn\n",
    "        h0 = torch.zeros((1, N, self.hidden_size)).to(device)\n",
    "        _, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # transform last hidden layer into 2nd rnn input\n",
    "        #print(\"HN:\", hn)\n",
    "        hn = hn.expand(L, N, self.hidden_size)\n",
    "        hn = hn.transpose(0,1)\n",
    "        #print(\"hn:\", hn)\n",
    "        # compute 2nd rnn\n",
    "        h2n, _ = self.rnn2(hn, h0)\n",
    "        \n",
    "        # decode sequence\n",
    "        y = self.linear(h2n)\n",
    "        return y, hn\n",
    "    \n",
    "class ComplexLSTM(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.lstm2 = torch.nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, L, Hin = x.size()\n",
    "        h0 = torch.zeros((1, N, self.hidden_size)).to(device)\n",
    "        c0 = torch.zeros(h0.size()).to(device)\n",
    "        _, (hn, _) = self.lstm(x, (h0, c0))\n",
    "    \n",
    "        xDummy = torch.zeros(x.size()).to(device)\n",
    "        cDummy = torch.zeros(hn.size()).to(device)\n",
    "        h2n, _ = self.lstm2(xDummy, (hn, cDummy))\n",
    "        \n",
    "        x = self.linear(h2n)\n",
    "        return x, hn\n",
    "    \n",
    "    def get_states_across_time(self, x):\n",
    "        h_c = None\n",
    "        h_list, c_list = list(), list()\n",
    "        with torch.no_grad():\n",
    "            for t in range(x.size(1)):\n",
    "                h_c = self.lstm(x[:, [t], :], h_c)[1]\n",
    "                h_list.append(h_c[0])\n",
    "                c_list.append(h_c[1])\n",
    "            h = torch.cat(h_list)\n",
    "            c = torch.cat(c_list)\n",
    "        return h, c\n",
    "\n",
    "N = 10 # tareas\n",
    "M = 3 # maquinas\n",
    "model = ThrashRNN(11, 4, 11).to(device)\n",
    "a = generateBatch(3, M, N).to(device)\n",
    "#print(a[1])\n",
    "print(a.size())\n",
    "print(\"no list\")\n",
    "y, yy = model(a)\n",
    "print(\"list\")\n",
    "print()\n",
    "#print(y)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2af09806",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.57 GiB (GPU 0; 5.94 GiB total capacity; 3.21 GiB already allocated; 68.00 MiB free; 4.79 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5083/1797887746.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Feed forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m#y_pred = y_pred[:, -1, :]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#print(y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5083/1906886379.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mxDummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mcDummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mh2n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxDummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcDummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    680\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.57 GiB (GPU 0; 5.94 GiB total capacity; 3.21 GiB already allocated; 68.00 MiB free; 4.79 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "N = 10 # tareas\n",
    "M = 3 # maquinas\n",
    "H = 10000 # hidden\n",
    "it = 100\n",
    "batchSize = 32\n",
    "\n",
    "model = ComplexLSTM(N+1, H, N+1).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr = 0.001)\n",
    "\n",
    "\n",
    "model.train()\n",
    "corrects = 0\n",
    "\n",
    "for i in range(it):\n",
    "    #get data\n",
    "    X = generateBatch(batchSize, M, N).to(device)\n",
    "    \n",
    "    # Feed forward\n",
    "    y_pred, h_pred = model(X)\n",
    "    #y_pred = y_pred[:, -1, :]\n",
    "    #print(y_pred)\n",
    "    \n",
    "    Y = X.argmax(dim = 2)\n",
    "    #Y = Y[-1]\n",
    "    #Y = Y[:, -1]\n",
    "    #print(Y)\n",
    "    # Loss Function\n",
    "    #print(Y.size(), y_pred.size())\n",
    "    loss = criterion(y_pred.view(32*12, -1), Y.view(-1))\n",
    "    \n",
    "    # Clear gradient\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # BackProp \n",
    "    loss.backward()\n",
    "    \n",
    "    #Gradient descent\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "a = generateBatch(1, M, N).to(device)\n",
    "printPred(a[0])\n",
    "b, _ = model(a)\n",
    "\n",
    "b = b.argmax(dim = 2)\n",
    "print(b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c24fa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine 1: \n",
      "Machine 2: 3 2 \n",
      "Machine 3: 5 9 10 6 4 8 1 7 \n",
      "False\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = generateBatch(1, M, N).to(device)\n",
    "printPred(a[0])\n",
    "b, _ = model(a)\n",
    "print(isValid(b[0], M, N))   \n",
    "b = b.argmax(dim = 2)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c1f0a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(166.6667, device='cuda:0') 0\n",
      "torch.Size([1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "it = 1000\n",
    "correct = 0\n",
    "valid = 0\n",
    "for i in range(1):\n",
    "    #get data\n",
    "    X = generateBatch(it, M, N).to(device)\n",
    "    \n",
    "    # Feed forward\n",
    "    y_pred, h_pred = model(X)\n",
    "    valid = [isValid(y, M, N) for y in y_pred]\n",
    "    #y_pred = y_pred[:, -1, :]\n",
    "    #print(y_pred)\n",
    "    y_pred = y_pred.argmax(dim = 2)\n",
    "    Y = X.argmax(dim = 2)\n",
    "    \n",
    "    correct = (y_pred == Y).sum() / 12\n",
    "vv = 0\n",
    "for v in valid:\n",
    "    if(v == True):\n",
    "        vv += 1\n",
    "valid = vv\n",
    "    \n",
    "print(correct, valid)\n",
    "print(h_pred[-1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35020e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
